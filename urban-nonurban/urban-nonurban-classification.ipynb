{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T16:35:04.319849Z","iopub.status.busy":"2024-04-17T16:35:04.319199Z","iopub.status.idle":"2024-04-17T16:35:16.419770Z","shell.execute_reply":"2024-04-17T16:35:16.418718Z","shell.execute_reply.started":"2024-04-17T16:35:04.319813Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n","  from pandas.core.computation.check import NUMEXPR_INSTALLED\n","C:\\Users\\ADMIN\\AppData\\Roaming\\Python\\Python39\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n","  from pandas.core import (\n"]}],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models, optimizers"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T16:35:21.073639Z","iopub.status.busy":"2024-04-17T16:35:21.072547Z","iopub.status.idle":"2024-04-17T16:35:21.129357Z","shell.execute_reply":"2024-04-17T16:35:21.128502Z","shell.execute_reply.started":"2024-04-17T16:35:21.073603Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 318 images belonging to 2 classes.\n","Found 78 images belonging to 2 classes.\n"]},{"name":"stderr","output_type":"stream","text":["c:\\Users\\ADMIN\\anaconda3\\lib\\site-packages\\keras\\preprocessing\\image.py:202: UserWarning: Using \".tiff\" files with multiple bands will cause distortion. Please verify your output.\n","  warnings.warn(\n"]}],"source":["train_dir = r'C:\\Users\\ADMIN\\Desktop\\Coastline Detection\\Coastline-Detection-Summer-Project-master\\ML Based\\urban-nonurban\\data\\train'\n","validation_dir = r'C:\\Users\\ADMIN\\Desktop\\Coastline Detection\\Coastline-Detection-Summer-Project-master\\ML Based\\urban-nonurban\\data\\val'\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest')\n","\n","test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescaling for validation data\n","\n","train_generator = train_datagen.flow_from_directory(\n","    train_dir,\n","    target_size=(224, 224),  # Size for VGGNet\n","    batch_size=20,\n","    class_mode='binary')\n","\n","validation_generator = test_datagen.flow_from_directory(\n","    validation_dir,\n","    target_size=(224, 224),\n","    batch_size=20,\n","    class_mode='binary')"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T16:35:34.476247Z","iopub.status.busy":"2024-04-17T16:35:34.475882Z","iopub.status.idle":"2024-04-17T16:35:34.539237Z","shell.execute_reply":"2024-04-17T16:35:34.538479Z","shell.execute_reply.started":"2024-04-17T16:35:34.476218Z"},"trusted":true},"outputs":[],"source":["from tensorflow.keras.layers import Input\n","\n","model = models.Sequential([\n","    Input(shape=(224, 224, 3)),  # Specify the input shape here\n","    layers.Conv2D(32, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(64, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Conv2D(128, (3, 3), activation='relu'),\n","    layers.MaxPooling2D((2, 2)),\n","    layers.Flatten(),\n","    layers.Dense(512, activation='relu'),\n","    layers.Dense(1, activation='sigmoid')  # For binary classification\n","])\n","\n","model.compile(loss='binary_crossentropy',\n","              optimizer=optimizers.RMSprop(learning_rate=1e-4),  # Correct parameter name\n","              metrics=['accuracy'])\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-17T16:35:37.236899Z","iopub.status.busy":"2024-04-17T16:35:37.236484Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/20\n","16/16 [==============================] - 9s 320ms/step - loss: 0.6643 - accuracy: 0.6352 - val_loss: 0.5297 - val_accuracy: 0.7564\n","Epoch 2/20\n","16/16 [==============================] - 5s 296ms/step - loss: 0.6113 - accuracy: 0.6509 - val_loss: 0.4994 - val_accuracy: 0.7949\n","Epoch 3/20\n","16/16 [==============================] - 5s 300ms/step - loss: 0.5877 - accuracy: 0.7264 - val_loss: 0.5752 - val_accuracy: 0.6795\n","Epoch 4/20\n","16/16 [==============================] - 5s 305ms/step - loss: 0.5616 - accuracy: 0.7484 - val_loss: 0.6128 - val_accuracy: 0.6667\n","Epoch 5/20\n","16/16 [==============================] - 5s 306ms/step - loss: 0.5595 - accuracy: 0.7421 - val_loss: 0.4617 - val_accuracy: 0.7949\n","Epoch 6/20\n","16/16 [==============================] - 5s 303ms/step - loss: 0.5515 - accuracy: 0.7547 - val_loss: 0.4208 - val_accuracy: 0.8205\n","Epoch 7/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.5393 - accuracy: 0.7516 - val_loss: 0.4468 - val_accuracy: 0.7949\n","Epoch 8/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.5277 - accuracy: 0.7421 - val_loss: 0.5014 - val_accuracy: 0.7051\n","Epoch 9/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.5346 - accuracy: 0.7453 - val_loss: 0.4326 - val_accuracy: 0.7949\n","Epoch 10/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.5527 - accuracy: 0.7201 - val_loss: 0.4367 - val_accuracy: 0.8205\n","Epoch 11/20\n","16/16 [==============================] - 5s 303ms/step - loss: 0.5163 - accuracy: 0.7579 - val_loss: 0.3632 - val_accuracy: 0.8333\n","Epoch 12/20\n","16/16 [==============================] - 5s 305ms/step - loss: 0.5524 - accuracy: 0.7138 - val_loss: 0.3979 - val_accuracy: 0.8333\n","Epoch 13/20\n","16/16 [==============================] - 5s 304ms/step - loss: 0.5198 - accuracy: 0.7736 - val_loss: 0.4303 - val_accuracy: 0.8077\n","Epoch 14/20\n","16/16 [==============================] - 5s 304ms/step - loss: 0.4807 - accuracy: 0.7862 - val_loss: 0.3993 - val_accuracy: 0.7949\n","Epoch 15/20\n","16/16 [==============================] - 5s 299ms/step - loss: 0.4787 - accuracy: 0.8145 - val_loss: 0.4069 - val_accuracy: 0.8077\n","Epoch 16/20\n","16/16 [==============================] - 5s 298ms/step - loss: 0.4979 - accuracy: 0.7642 - val_loss: 0.4349 - val_accuracy: 0.7949\n","Epoch 17/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.5120 - accuracy: 0.7421 - val_loss: 0.3942 - val_accuracy: 0.8077\n","Epoch 18/20\n","16/16 [==============================] - 5s 301ms/step - loss: 0.5057 - accuracy: 0.7484 - val_loss: 0.3719 - val_accuracy: 0.7949\n","Epoch 19/20\n","16/16 [==============================] - 5s 303ms/step - loss: 0.4517 - accuracy: 0.8050 - val_loss: 0.3704 - val_accuracy: 0.8333\n","Epoch 20/20\n","16/16 [==============================] - 5s 305ms/step - loss: 0.4564 - accuracy: 0.7956 - val_loss: 0.5619 - val_accuracy: 0.7436\n"]}],"source":["history = model.fit(\n","    train_generator,  \n","    epochs=20,\n","    validation_data=validation_generator,\n","    )  "]},{"cell_type":"markdown","metadata":{},"source":["testing different models"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:20:23.357583Z","iopub.status.busy":"2024-04-04T06:20:23.356911Z","iopub.status.idle":"2024-04-04T06:20:24.491550Z","shell.execute_reply":"2024-04-04T06:20:24.490557Z","shell.execute_reply.started":"2024-04-04T06:20:23.357550Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, models, optimizers\n","from tensorflow.keras.applications import ResNet50, MobileNetV2, EfficientNetB0\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","from sklearn.metrics import classification_report, accuracy_score"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:20:26.806646Z","iopub.status.busy":"2024-04-04T06:20:26.805847Z","iopub.status.idle":"2024-04-04T06:20:29.668870Z","shell.execute_reply":"2024-04-04T06:20:29.667800Z","shell.execute_reply.started":"2024-04-04T06:20:26.806600Z"},"trusted":true},"outputs":[],"source":["def build_model(model_name, input_shape=(224, 224, 3)):\n","    if model_name == 'CustomCNN':\n","        base_model = Sequential([\n","            layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n","            layers.MaxPooling2D((2, 2)),\n","            layers.Conv2D(64, (3, 3), activation='relu'),\n","            layers.MaxPooling2D((2, 2)),\n","            layers.Conv2D(128, (3, 3), activation='relu'),\n","            layers.MaxPooling2D((2, 2)),\n","            layers.Flatten()  # This correctly flattens the output for the Dense layer\n","        ])\n","    else:\n","        if model_name == 'ResNet50':\n","            pre_model = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n","        elif model_name == 'MobileNetV2':\n","            pre_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)\n","        elif model_name == 'EfficientNetB0':\n","            pre_model = EfficientNetB0(include_top=False, weights='imagenet', input_shape=input_shape)\n","        base_model = Sequential([\n","            pre_model,\n","            GlobalAveragePooling2D()  # Ensures compatibility with the GlobalAveragePooling2D layer\n","        ])\n","    \n","    model = Sequential([\n","        base_model,\n","        Dense(1, activation='sigmoid')\n","    ])\n","    \n","    model.compile(optimizer='adam',\n","                  loss='binary_crossentropy',\n","                  metrics=['accuracy'])\n","    return model\n","\n","# Now, let's initialize the models correctly\n","input_shape=(224, 224, 3)\n","models_to_train = {\n","    #'ResNet50': build_model('ResNet50', input_shape),\n","    'CustomCNN': build_model('CustomCNN', input_shape),\n","    #'MobileNetV2': build_model('MobileNetV2', input_shape),\n","    #'EfficientNetB0': build_model('EfficientNetB0', input_shape)\n","}\n"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-04-04T06:44:46.119751Z","iopub.status.busy":"2024-04-04T06:44:46.119326Z","iopub.status.idle":"2024-04-04T06:45:53.050035Z","shell.execute_reply":"2024-04-04T06:45:53.049167Z","shell.execute_reply.started":"2024-04-04T06:44:46.119719Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Training CustomCNN...\n","Epoch 1/20\n","16/16 [==============================] - 8s 310ms/step - loss: 0.6881 - accuracy: 0.6321 - val_loss: 0.5095 - val_accuracy: 0.8462\n","Epoch 2/20\n","16/16 [==============================] - 5s 303ms/step - loss: 0.6067 - accuracy: 0.7138 - val_loss: 0.4941 - val_accuracy: 0.7692\n","Epoch 3/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.5666 - accuracy: 0.7327 - val_loss: 0.4377 - val_accuracy: 0.8333\n","Epoch 4/20\n","16/16 [==============================] - 5s 299ms/step - loss: 0.5439 - accuracy: 0.7547 - val_loss: 0.4133 - val_accuracy: 0.7821\n","Epoch 5/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.5231 - accuracy: 0.7547 - val_loss: 0.3935 - val_accuracy: 0.8205\n","Epoch 6/20\n","16/16 [==============================] - 5s 301ms/step - loss: 0.5433 - accuracy: 0.7421 - val_loss: 0.4211 - val_accuracy: 0.7949\n","Epoch 7/20\n","16/16 [==============================] - 5s 299ms/step - loss: 0.5303 - accuracy: 0.7704 - val_loss: 0.3808 - val_accuracy: 0.7949\n","Epoch 8/20\n","16/16 [==============================] - 5s 302ms/step - loss: 0.5096 - accuracy: 0.7862 - val_loss: 0.3618 - val_accuracy: 0.7949\n","Epoch 9/20\n","16/16 [==============================] - 5s 293ms/step - loss: 0.4956 - accuracy: 0.7767 - val_loss: 0.3666 - val_accuracy: 0.8077\n","Epoch 10/20\n","16/16 [==============================] - 5s 294ms/step - loss: 0.5443 - accuracy: 0.7516 - val_loss: 0.4741 - val_accuracy: 0.8333\n","Epoch 11/20\n","16/16 [==============================] - 5s 299ms/step - loss: 0.5318 - accuracy: 0.7610 - val_loss: 0.4058 - val_accuracy: 0.8333\n","Epoch 12/20\n","16/16 [==============================] - 5s 296ms/step - loss: 0.5352 - accuracy: 0.7390 - val_loss: 0.4129 - val_accuracy: 0.7949\n","Epoch 13/20\n","16/16 [==============================] - 5s 295ms/step - loss: 0.4942 - accuracy: 0.7925 - val_loss: 0.3596 - val_accuracy: 0.8077\n","Epoch 14/20\n","16/16 [==============================] - 5s 301ms/step - loss: 0.4976 - accuracy: 0.7830 - val_loss: 0.3498 - val_accuracy: 0.8333\n","Epoch 15/20\n","16/16 [==============================] - 5s 297ms/step - loss: 0.4865 - accuracy: 0.7893 - val_loss: 0.3655 - val_accuracy: 0.8077\n","Epoch 16/20\n","16/16 [==============================] - 5s 296ms/step - loss: 0.4701 - accuracy: 0.7925 - val_loss: 0.3287 - val_accuracy: 0.8462\n","Epoch 17/20\n","16/16 [==============================] - 5s 295ms/step - loss: 0.4797 - accuracy: 0.8176 - val_loss: 0.3731 - val_accuracy: 0.8205\n","Epoch 18/20\n","16/16 [==============================] - 5s 293ms/step - loss: 0.4990 - accuracy: 0.7516 - val_loss: 0.3514 - val_accuracy: 0.7821\n","Epoch 19/20\n","16/16 [==============================] - 5s 295ms/step - loss: 0.4540 - accuracy: 0.7987 - val_loss: 0.3444 - val_accuracy: 0.8718\n","Epoch 20/20\n","16/16 [==============================] - 5s 303ms/step - loss: 0.5165 - accuracy: 0.7484 - val_loss: 0.3176 - val_accuracy: 0.8333\n","4/4 [==============================] - 1s 211ms/step - loss: 0.3176 - accuracy: 0.8333\n","CustomCNN - Loss: 0.3176411986351013, Accuracy: 0.8333333134651184\n"]}],"source":["results = {}\n","for name, model in models_to_train.items():\n","    print(f\"Training {name}...\")\n","    # Assuming train_generator and validation_generator are defined as before\n","    history = model.fit(train_generator,\n","                        epochs=20,  # Adjust based on your needs\n","                        validation_data=validation_generator)\n","    \n","    # Evaluate the model\n","    val_loss, val_accuracy = model.evaluate(validation_generator)\n","    results[name] = {'Validation Loss': val_loss, 'Validation Accuracy': val_accuracy}\n","\n","# Print the comparison\n","for name, metrics in results.items():\n","    print(f\"{name} - Loss: {metrics['Validation Loss']}, Accuracy: {metrics['Validation Accuracy']}\")"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["model.save('natural-built-classifier.h5')"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4701691,"sourceId":7987221,"sourceType":"datasetVersion"},{"datasetId":4818692,"sourceId":8148166,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":4}
